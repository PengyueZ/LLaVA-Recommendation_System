# Multi-Modal Product Recommendation System with Vision-Language Model

An end-to-end multi-modal product recommendation system that leverages vision-language models to integrate product images and textual descriptions for highly accurate, interpretable, and scalable recommendations.

## Project Overview

This project builds a state-of-the-art product recommendation system by combining:

- **CLIP (ViT-based encoder)** for multi-modal embedding of product images and textual descriptions.
- **LLaVA (LLaMA-based vision-language model)** for generating product-aware rationales and explanations, enhancing interpretability.
- **LoRA-based instruction tuning** using synthetic GPT-generated QA pairs to boost model generalization and recommendation accuracy.
- **FAISS-FastAPI scalable search pipeline** enabling real-time product search across 1M+ items with sub-100ms response time.
- **MLflow-based experiment tracking** and ablation studies for systematic evaluation and continuous improvement.
- **Dockerized deployment** for reproducibility, CI/CD integration, and production-grade deployment.

---

## Key Features

- ðŸ“¦ **Multi-modal Embedding**: Joint representation learning using CLIP to encode product images and descriptions into a shared latent space.
- ðŸ§  **Explainable Recommendations**: LLaVA-generated rationales provide users with human-readable explanations for recommendations.
- ðŸŽ¯ **Instruction-tuning for QA**: Fine-tuning with GPT-generated synthetic QA pairs via LoRA improves alignment with product-specific queries.
- ðŸš€ **Real-time Search**: Efficient FAISS-based similarity search with FastAPI backend supports sub-100ms retrieval across 1M+ product embeddings.
- ðŸ“Š **Evaluation and Offline Testing**: User interaction simulations and A/B testing yield 92% average precision and 10% reduction in irrelevant recommendations compared to baseline.
- ðŸ”¬ **Ablation Studies**: Extensive experiments to optimize cross-modal generalization performance.
- ðŸ“¦ **Reproducibility**: Fully containerized using Docker for seamless deployment and CI/CD pipelines.

---

## Dataset
- **Amazon Reviews 2023 Dataset**
  Used both the product metadata (images, titles, descriptions) and review texts for contrastive learning and fine-tuning.
- Synthetic QA pairs generated via GPT for instruction-tuning.

---

## System Architecture

Data Collection â†’ Data Preprocessing â†’ CLIP-based Embedding â†’ LoRA Instruction-Tuning â†’ LLaVA-based Explanation â†’ FAISS Indexing â†’ FastAPI Deployment â†’ Dockerized CI/CD Pipeline

---

## Tech Stack

- **Frameworks/Libraries**: PyTorch, HuggingFace Transformers, CLIP, LLaVA, FAISS, FastAPI, MLflow
- **Deployment**: Docker, CI/CD, Kubernetes (optional)
- **Data**: Amazon Reviews 2023, GPT-synthesized QA data
